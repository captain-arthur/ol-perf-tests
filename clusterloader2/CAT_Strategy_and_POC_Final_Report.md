# 🚀 Kubernetes Cluster Acceptance Test (CAT) Strategy & PoC Report

## 1. 개요 (Executive Summary)
본 보고서는 성공적인 클러스터 인수 테스트(CAT, Cluster Acceptance Test) 수행을 위해 **ClusterLoader2(CL2)**를 활용한 기술 검토 결과와 실무적인 적용 전략을 제안합니다. 최근 수행한 네트워크 성능 PoC 결과를 바탕으로, 오픈소스 도구의 한계점을 극복하고 실제 운영 환경에서 신뢰할 수 있는 성능 지표를 확보하는 방안을 다룹니다.

---

## 2. 우리가 클러스터 인수 테스트(CAT)를 해야 하는 이유
기술적인 관점에서 클러스터를 단순히 '성공적으로 배포'하는 것과 '서비스가 가능한 상태'임은 별개입니다.

*   **성능 Baseline 확립**: 애플리케이션 투입 전, 인프라 자체가 제공할 수 있는 최대 성능(L3/L4/L7 대역폭, API 처리량)의 기준점을 잡아야 이후 발생하는 장애가 앱 문제인지 인프라 문제인지 판별 가능합니다.
*   **SLO(Service Level Objective) 준수 검증**: "포드 생성 5초 이내 완료", "API 응답 99th percentile 1초 이내" 등 쿠버네티스 공식 표준에 부합하는지 확인합니다.
*   **인프라 병목 조기 발견**: 커널 파라미터 최적화(Sysctl), 네트워크 CNI 설정, 스토리지 IOPS 등 운영 중에 바꾸기 어려운 핵심 설정을 인수 단계에서 검증합니다.
*   **Vendor/On-prem 신뢰성 검증**: 제공받은 인프라가 계약된 사양(예: 25Gbps 대역폭)을 실제로 제공하는지 화이트박스 테스트를 통해 증명합니다.

---

## 3. ClusterLoader2 시나리오 조사 결과
CL2는 단순한 부하 발생기가 아니라, 업스트림(Upstream) K8s 성능 측정 가이드라인을 코드로 구현한 프레임워크입니다.

### 3-1. 주요 내장 시나리오
| 시나리오 | 테스트 내용 | 주요 측정 항목 (Measurements) |
| :--- | :--- | :--- |
| **Load Test** | 지속적인 오브젝트 생성/수정/삭제 부하 | API Responsiveness, Informer Latency, Pod Startup |
| **Density Test** | 노드당 포드 밀집도 극대화 (30~100 pods/node) | Scheduling Throughput, Pod Startup Latency |
| **Network Test** | 포드 간 대역폭 및 지연시간 측정 | TCP/UDP Throughput, HTTP Latency |
| **Chaos Monkey** | 부하 중 임의의 노드 장애 발생 | Recovery Time, API Availability during failure |
| **Throughput** | 순수 스케줄러 및 노드 등록 성능 | Registration rate, Scheduling rate |

### 3-2. 네트워크 성능 측정 가능성 (PoC 결과)
*   **가능성**: **매우 높음**. 실제 PoC를 통해 1:1, N:M 포드 간 통신 테스트가 가능함을 증명했습니다.
*   **성과**: 초기 구동 실패를 패치하여 **약 21 Gbps (환경에 따라 4.8 GB/s 이상)**의 실측 데이터를 확보했습니다.
*   **결론**: CL2는 단순한 K8s 관리 도구를 넘어, 네트워크 벤치마킹 도구(iperf/netperf)를 내재화하여 클러스터 수준의 L4 성능 측정이 가능한 최적의 도구입니다.

---

## 4. 실무적 관점의 CAT 전략 제안
단순히 도구를 돌리는 것이 아니라, 단계별로 접근하는 **3-Step CAT 전략**을 제안합니다.

### Step 1: Baseline 측정 (Infrastructure Focused)
*   **목적**: 순수 인프라 리소스(CPU/Mem/Network) 성능 확인.
*   **수행**: `network` 시나리오 및 `node-throughput` 시나리오 실행.
*   **기대 효과**: 네트워크 대역폭 및 API 서버의 기초 체력 확인.

### Step 2: 클러스터 밀도 테스트 (Scalability Focused)
*   **목적**: 클러스터가 커졌을 때 관리 컴포넌트(Scheduler, Controller Manager)의 한계 확인.
*   **수행**: `density` 및 `load` 시나리오 실행.
*   **기대 효과**: "우리 클러스터는 노드당 최대 X개의 포드까지 안정적으로 띄울 수 있다"는 한계치 설정.

### Step 3: 복원력 테스트 (Resilience Focused)
*   **목적**: 갑작스러운 장애 상황에서도 성능 저하가 SLO 범위 내에 있는지 확인.
*   **수행**: `load` + `chaosmonkey` 결합 시나리오 실행.
*   **기대 효과**: 장애 복구 중에도 서비스 가용성이 유지되는지 실무적으로 증명.

---

## 5. 기술적 가이드 및 유지보수 방안 (Lessons Learned)
ClusterLoader2는 강력하지만 관리가 까다로운 도구입니다. 지속적인 활용을 위해 다음 사항을 제언합니다.

*   **Upstream 의존성 주의**: 보안 정책 강화(`safetext` 등)로 인해 기존 템플릿이 갑자기 동작하지 않을 수 있습니다. 본 팀에서 관리하는 **'Golden Manifests' (패치 처리된 안전한 매니페스트)**를 별도 관리해야 합니다.
*   **권한 및 성능 프로파일링**: 워커 파드의 RBAC 권한(ServiceAccount)과 리소스 할당량(Limits)이 작으면 실제 성능을 측정할 수 없습니다. 이번 PoC에서 적용한 리소스 최적화 설정을 표준으로 채택해야 합니다.

## 6. 결론
ClusterLoader2는 불친절하지만 강력한 '전문가용 도구'입니다. 이번 PoC를 통해 그 불친절함(보안 정책, 권한 문제)을 기술적으로 극복하는 법을 체득했으며, 이를 통해 **팀 자체적인 클러스터 검증 프로세스를 구축할 전기를 마련**했습니다.

우리는 이제 막연한 신뢰가 아닌, **데이터에 기반한 클러스터 인수**가 가능합니다.

---

---

## 7. 가상 Q&A (보고용 핵심 질의응답)

> [!NOTE]
> 본 섹션은 전문 용어를 일상 언어로 풀어서 설명하여 의사결정권자의 이해를 돕기 위해 작성되었습니다.

### Q1. 신규 클러스터 생성 시 네트워크 테스트를 바로 할 수 있습니까?
**A**: 네, 가능합니다. 
*   **쉬운 설명**: 클러스터가 어디에 있든(자사 전산실, 클라우드 등), 우리가 그 클러스터를 관리할 수 있는 **'열쇠(kubeconfig)'**만 있다면 바로 테스트가 가능합니다. 
*   **기술적 보충**: CL2의 `skeleton` 모드는 "이미 만들어진 클러스터에 접속하여 테스트만 수행"하는 기능입니다. 접속 정보 파일인 `kubeconfig` 하나만 있으면 외부에서 원격으로 테스트를 명령하고 결과를 가져올 수 있습니다.

### Q2. 네트워크 테스트는 구체적으로 어떤 과정을 거쳐 진행됩니까?
**A**: '자동화된 속도 측정' 과정으로 이해하시면 쉽습니다.
1.  **배포**: 테스트 도구가 클러스터 내부에 데이터를 주고받을 **측정용 파드(통신 유닛)**들을 자동으로 띄웁니다.
2.  **측정**: 각 유닛들 사이에서 데이터를 최대한 밀어 넣어보며 실제 속도를 잽니다. 이때 `iperf`나 `netperf` 같은 전문 **'인터넷 속도 측정 엔진'**을 사용합니다.
3.  **수집**: 측정된 결과값은 쿠버네티스 전용 **'디지털 성적표(CRD)'**에 기록되어 마스터 서버로 자동 취합됩니다.
4.  **분석**: 최종적으로 사람이 읽기 쉬운 통합 보고서(JSON/HTML)로 변환됩니다.

### Q3. 네트워크 구성 요소(CNI, Ingress 등)도 테스트가 가능합니까?
**A**: 네, 실제 데이터가 이동하는 경로별로 검증이 가능합니다.
*   **CNI(컴퓨터 간 통신 기술)**: 클러스터 내부의 파드끼리 직접 소통하게 하여, 통신 인프라 자체의 속도를 잽니다.
*   **Ingress(외부 진입로)**: 외부 사용자가 접속하는 경로와 똑같이 트래픽을 흘려보내어, 입구에서 발생하는 병목 현상을 확인합니다.

### Q4. 네트워크 테스트에서 구체적으로 무엇을 확인해야 합니까?
**A**: 단순한 통신 여부가 아니라 **'인프라가 제 실력을 내고 있는가'**를 봅니다.
*   **예시**: 만약 우리 네트워크 장비가 **25Gbps(초당 약 3.1GB)** 사양이라면, 실제 테스트에서 이 수치의 80~90%가 나오는지 확인해야 합니다. 만약 이보다 현저히 낮다면, 하드웨어 성능 부족이 아니라 설정 값(커널 파라미터 등)에 문제가 있음을 의미합니다.

### Q5. 테스트 결과로 합격/불합격을 결정할 수 있습니까?
**A**: 네, **'성능 커트라인'**을 설정할 수 있습니다.
*   우리가 사전에 "최소 10Gbps 속도는 나와야 한다"라고 기준을 정해두면, 도구가 테스트 후 자동으로 기준 미달 시 'FAIL(탈락)' 판정을 내립니다. 이 결과는 서버 사양을 높여야 할지(Scale-up), 아니면 현재 사양으로 충분한지(Scale-out)를 결정하는 객관적인 **'데이터 증거'**가 됩니다.

### Q6. 실무적인 관점에서 이 테스트가 왜 중요합니까?
**A**: 나중에 발생할 **'범인 찾기'** 시간을 획기적으로 줄여줍니다.
*   서비스 운영 중에 네트워크가 느려지면 인프라 탓인지, 앱 탓인지 싸우는 경우가 많습니다. 클러스터 인수 때 CL2로 '인프라 자체의 최고 속도'를 기록해두면, 나중에 문제가 생겼을 때 "인프라는 원래 이 속도가 나오니, 앱 쪽을 확인해달라"라고 명확히 말할 수 있는 **'원본 대조표'**가 됩니다.

### Q7. 단순히 수동으로 속도 측정을 하는 것과 무엇이 다릅니까?
**A**: 실제 운영 환경과 똑같은 **'부하 상황'**을 재현할 수 있습니다.
*   수동 측정은 1~2개 파드만 사용하지만, CL2는 수백 개의 파드가 동시에 대화를 나누는 복잡한 상황을 만들 수 있습니다. 즉, 평소에는 괜찮다가 사람이 몰릴 때만 발생하는 교묘한 인프라 결함을 미리 찾아낼 수 있습니다.

### Q8. 클러스터가 커져도 이 테스트를 믿을 수 있습니까?
**A**: CL2는 전 세계 쿠버네티스 개발자들이 대규모 환경(노드 1,000개 이상)을 테스트하기 위해 만든 도구입니다. 따라서 우리 클러스터 규모가 얼마나 커지든 그에 맞는 신뢰할 수 있는 성능 데이터를 제공합니다.

### Q9. 여러 개의 클러스터를 운영할 때도 유용합니까?
**A**: 여러 클러스터에 동일한 테스트를 실행하여 **'품질 균일화'**를 할 수 있습니다. A 클러스터는 20Gbps가 나오는데 B 클러스터는 10Gbps만 나온다면, B 클러스터의 설정이 잘못되었음을 즉시 발견할 수 있습니다.

### Q10. 테스트 도중 다른 서비스에 방해가 되지는 않습니까?
**A**: 도구가 사용하는 통신이나 연산의 **'우선순위(Priority)'**를 조절할 수 있습니다. 운영 중인 서버라면 아주 낮은 순위로 조용히 테스트하고, 인수 단계에서는 가장 높은 순위로 최대한의 성능을 뽑아내어 한계를 시험하게 할 수 있습니다.

### Q11. 대역폭(Throughput) 외에 또 무엇을 알 수 있습니까?
**A**: **'응답 지연 시간(Latency)'**을 알 수 있습니다.
*   데이터 양은 많아도 실제 응답이 한참 뒤에 온다면 웹사이트가 버벅거리게 됩니다. CL2는 데이터가 가는 양뿐만 아니라, 얼마나 빠르게 답장이 오는지(지연 시간)도 0.001초 단위로 정밀하게 수집합니다.

### Q12. 이 도구의 결과가 대외적으로도 공신력이 있습니까?
**A**: ClusterLoader2는 쿠버네티스 커뮤니티의 **'공식 성능 측정 도구'**입니다. 구글이나 MS 같은 클라우드 기업들도 이를 사용하여 성능을 선언합니다. 따라서 우리가 도출한 결과는 벤더사(HP, Dell 등)나 사내 타 팀에 제시할 때 가장 강력하고 객관적인 기술 근거가 됩니다.
